{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "#import stuff\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import  GradientBoostingRegressor\n",
    "import numpy as np\n",
    "from sklearn import ensemble , preprocessing\n",
    "import  xgboost as xgb\n",
    "import time\n",
    "import pickle\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.linear_model import LinearRegression \n",
    "from sklearn import  svm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import cross_validation\n",
    "import matplotlib.pyplot  as plt\n",
    "from IPython.display import display\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from __future__ import division\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#define root mean  squared loss   error metric  used in the competition\n",
    "def  rmsle(y,yhat):\n",
    "    from math import log , sqrt\n",
    "    assert len(y)==len(yhat)\n",
    "    yhat[yhat<0]=0\n",
    "    rmsle=0\n",
    "    for pair in zip(y,yhat):\n",
    "        logdiff=log(1+pair[1])-log(1+pair[0])\n",
    "        rmsle+=logdiff*logdiff\n",
    "      \n",
    "    rmsle=sqrt(rmsle/len(yhat))\n",
    "    return rmsle\n",
    "        \n",
    "from sklearn.metrics import make_scorer    \n",
    "rmsle_loss=make_scorer(rmsle,greater_is_beter=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30213, 37)\n",
      "(30235, 37)\n"
     ]
    }
   ],
   "source": [
    "#read  data\n",
    "train=pd.read_csv('d:/buldozer/generateTrain.csv')\n",
    "test=pd.read_csv('d:/buldozer/generateTest.csv')\n",
    "cost=train['cost']\n",
    "test=test.drop(['tube_assembly_id','component_id_7','component_id_8','quantity_8','quantity_7','quantity_6','quantity_5'],axis=1)\n",
    "train=train.drop(['cost','tube_assembly_id','component_id_7','component_id_8','quantity_8','quantity_7','quantity_6','quantity_5'],axis=1)\n",
    "trainvec=np.array(train)\n",
    "testvec=np.array(test)\n",
    "cost=np.array(cost)\n",
    "print(train.shape)\n",
    "print(test.shape)\n",
    "               \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30213L, 38L)\n",
      "(30235L, 38L)\n",
      "(30213L, 1L)\n"
     ]
    }
   ],
   "source": [
    "#read second data set in order to  tune it   on cross validation and prepare it  for   generating   same learners\n",
    "#but on  different  data set vor  diversity\n",
    "trainvec2=pd.read_csv('d:/buldozer1/trainvec2.csv')\n",
    "testvec2=pd.read_csv('d:/buldozer1/testvec2.csv')\n",
    "cost2=pd.read_csv('d:/buldozer1/cost2.csv')\n",
    "trainvec2=np.array(trainvec2)\n",
    "testvec2=np.array(testvec2)\n",
    "cost2=np.array(cost2)\n",
    "print(trainvec2.shape)\n",
    "print(testvec2.shape)\n",
    "print(cost2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def ada_learning(y, train, test,trees):\n",
    "    label_log = np.log1p(y)\n",
    "    #1'd model\n",
    "    #DecisionTreeRegressor= DecisionTreeRegressor(max_depth=4)\n",
    "    ada = AdaBoostRegressor(DecisionTreeRegressor(max_depth=15),\n",
    "                          n_estimators=trees)   \n",
    "    ada.fit(train, label_log)\n",
    "    p=np.expm1(ada.predict(test))\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#define  xgboost function\n",
    "def x_b(y, train, test,trees):\n",
    "    labels=np.log1p(y)\n",
    "    params={}\n",
    "    params[\"objective\"] = \"reg:linear\"\n",
    "    params[\"eta\"] = 0.02\n",
    "    params[\"min_child_weight\"] = 7\n",
    "    params[\"subsample\"] = 0.7\n",
    "    params[\"colsample_bytree\"] = 0.65\n",
    "    params[\"scale_pos_weight\"] = 0.5\n",
    "    params[\"silent\"] = 1\n",
    "    params[\"max_depth\"] = 7\n",
    "    params[\"seed\"]=2\n",
    "    plst = list(params.items())\n",
    "    xgtrain=xgb.DMatrix(train, label=labels)\n",
    "    xgtest = xgb.DMatrix(test)\n",
    "    num_rounds = trees\n",
    "    model = xgb.train(plst, xgtrain, num_rounds)\n",
    "    prediction=model.predict(xgtest)\n",
    "    prediction=np.expm1(prediction)\n",
    "    return prediction\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#define random forest   regressors \n",
    "def  random_forest(y,train , test, trees):\n",
    "    labels=np.log1p(y)\n",
    "    rf=RandomForestRegressor(n_estimators=trees,n_jobs=-1)\n",
    "    rf.fit(train,labels)\n",
    "    p=rf.predict(test)\n",
    "    p=np.expm1(p)\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def  random_forest(y,train , test, trees):\n",
    "    labels=np.log1p(y)\n",
    "    rf=RandomForestRegressor(n_estimators=trees,n_jobs=-1)\n",
    "    rf.fit(train,labels)\n",
    "    p=rf.predict(test)\n",
    "    p=np.expm1(p)\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#define  gradient boosting  machines\n",
    "def  gbm(y,train ,test,trees,max_depth):\n",
    "    labels=np.log1p(y)\n",
    "    params = {'n_estimators': trees, 'max_depth': max_depth, 'min_samples_split': 6,\n",
    "          'learning_rate': 0.01, 'loss': 'lad', 'subsample': 0.7}\n",
    "    gbr = GradientBoostingRegressor(**params)\n",
    "    gbr.fit(train,labels)\n",
    "    prediction=gbr.predict(test)\n",
    "    predictions=np.expm1(prediction)\n",
    " \n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('eroare ', [0.28767955785945454, 0.2951165063996632, 0.2940179846214483, 0.2866478754034704])\n",
      "('mean of error', 0.29086548107100912)\n"
     ]
    }
   ],
   "source": [
    "#look   how scores  are  going on on  cross validation   according to  number  of  trees\n",
    "cross_error=[]\n",
    "rand=np.random.RandomState(1234)\n",
    "for cv in  range(1,5):\n",
    "    idx_tr,idx_ts=train_test_split(np.arange(train1.shape[0]),train_size=0.3,random_state=rand)\n",
    "    cv_train=train1[idx_tr]\n",
    "    cv_test=train1[idx_ts]\n",
    "    cv_train_y=cost[idx_tr]\n",
    "    cv_test_y=cost[idx_ts]\n",
    "    #pred_cv=random_forest(cv_train_y,cv_train,cv_test,1000)\n",
    "    pred_cv1=x_b(cv_train_y,cv_train,cv_test,8000)\n",
    "    pred_cv2=x_b(cv_train_y,cv_train,cv_test,5000)\n",
    "    pred_cv3=x_b(cv_train_y,cv_train,cv_test,6000)\n",
    "    pred_cv4=x_b(cv_train_y,cv_train,cv_test,7000)\n",
    "    pred_cv5=x_b(cv_train_y,cv_train,cv_test,4000)\n",
    "    pred_cv6=x_b(cv_train_y,cv_train,cv_test,9000)\n",
    "    pred_cv=(pred_cv1+pred_cv2+pred_cv3+pred_cv4+pred_cv5+pred_cv6)/6\n",
    "    #pred_cv2=gbm(cv_train_y,cv_train,cv_test,5000,13)\n",
    "  \n",
    "  \n",
    "    err=rmsle(pred_cv,cv_test_y)\n",
    "    cross_error.append(err)\n",
    "print(\"eroare \",cross_error)    \n",
    "print(\"mean of error\",np.mean(cross_error))    \n",
    "                                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-80d618e60ab7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#getting weights  for  small ensamble of  2 learners\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#split data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mrand\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRandomState\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1234\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mtrain_index\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainvec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtrain_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrainvec\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcost\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "#getting weights  for  small ensamble of  2 learners\n",
    "#split data\n",
    "rand=np.random.RandomState(1234)\n",
    "train_index,test_index=train_test_split(np.arange(trainvec.shape[0]),train_size=0.3,random_state=rand)\n",
    "train_x,train_y=trainvec[train_index],cost[train_index]\n",
    "test_x,test_y=trainvec[test_index],cost[test_index]\n",
    "#build  the regressor learners\n",
    "predictions=[]\n",
    " \n",
    "#for  data set  2\n",
    "predictions.append(x_b(train_y[:,0],train_x,test_x,1000))\n",
    "predictions.append(x_b(train_y[:,0],train_x,test_x,2000))\n",
    "predictions.append(x_b(train_y[:,0],train_x,test_x,3000))\n",
    "predictions.append(x_b(train_y[:,0],train_x,test_x,4000))\n",
    "predictions.append(x_b(train_y[:,0],train_x,test_x,5500))\n",
    "predictions.append(ada_learning(train_y[:,0],train_x,test_x,100))\n",
    "predictions.append(ada_learning(train_y[:,0],train_x,test_x,50))\n",
    "predictions.append(ada_learning(train_y[:,0],train_x,test_x,300))\n",
    "predictions.append(ada_learning(train_y[:,0],train_x,test_x,500))\n",
    "predictions.append(random_forest(train_y[:,0],train_x,test_x,50))\n",
    "predictions.append(random_forest(train_y[:,0],train_x,test_x,100))\n",
    "predictions.append(random_forest(train_y[:,0],train_x,test_x,500))\n",
    "predictions.append(gbm(train_y[:,0],train_x,test_x,4000,10))\n",
    "predictions.append(gbm(train_y[:,0],train_x,test_x,2000,12))\n",
    "predictions.append(gbm(train_y[:,0],train_x,test_x,5000,9))\n",
    "predictions.append(gbm(train_y[:,0],train_x,test_x,1000,9))    \n",
    "predictions.append(gbm(train_y[:,0],train_x,test_x,750,7))\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensamble Score: 1.07492425876\n",
      "Best Weights: [ 0.          0.          0.         -0.          0.         -0.         -0.\n",
      "  0.          0.88720023 -0.         -0.         -0.          0.         -0.\n",
      " -0.         -0.          0.          0.          0.         -0.          0.\n",
      "  0.         -0.         -0.         -0.         -0.         -0.         -0.\n",
      "  0.         -0.         -0.          0.        ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  0.        ,  0.        , -0.        ,  0.        ,\n",
       "       -0.        , -0.        ,  0.        ,  0.88720023, -0.        ,\n",
       "       -0.        , -0.        ,  0.        , -0.        , -0.        ,\n",
       "       -0.        ,  0.        ,  0.        ,  0.        , -0.        ,\n",
       "        0.        ,  0.        , -0.        , -0.        , -0.        ,\n",
       "       -0.        , -0.        , -0.        ,  0.        , -0.        ,\n",
       "       -0.        ,  0.        ])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define  the  wheighted  root mean squared logharitmic  metric\n",
    "pred=len(predictions)\n",
    "np.set_printoptions(suppress=True)\n",
    "from scipy.optimize import  minimize\n",
    "from scipy import optimize\n",
    "from scipy.optimize import  leastsq\n",
    "def weighted_rmsle(weights):\n",
    "    final_prediction=0\n",
    "    for weight,prediction in zip(weights,predictions):\n",
    "        final_prediction+=weight*prediction\n",
    "    \n",
    " \n",
    "    return rmsle(final_prediction,cost)\n",
    "    # return mean_squared_error(final_prediction,test_y)\n",
    "#set starting  values\n",
    "starting_values=[0.1]*len(predictions)\n",
    "#set constraints\n",
    "cons = ({'type':'eq','fun':lambda w: 1-sum(w)})\n",
    "#set weights bound  between  0 and  1 open interval\n",
    "bounds=[(0,1)]*len(predictions)\n",
    "res=minimize(weighted_rmsle,starting_values,method='SLSQP',bounds=bounds )\n",
    " \n",
    "\n",
    " \n",
    "print('Ensamble Score: {best_score}'.format(best_score=res['fun']))\n",
    "print('Best Weights: {weights}'.format(weights=res['x']))\n",
    "weights=res['x']\n",
    "weights \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions=[]\n",
    "newTrain=pd.read_csv('d:/buldozer/newTrain.csv')\n",
    "newTest=pd.read_csv('d:/buldozer/newTest.csv')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train1=np.hstack((newTrain,train))\n",
    "test1=np.hstack((newTest,test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p1=x_b(cost,train1,test1,4000)\n",
    "p2=x_b(cost,train1,test1,5000)\n",
    "p3=x_b(cost,train1,test1,6000)\n",
    "p4=x_b(cost,train1,test1,7000)\n",
    "p5=x_b(cost,train1,test1,8000)\n",
    "p6=x_b(cost,train1,test1,9000)\n",
    "p=(p1+p2+p3+p4+p5+p6)/6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(p).to_csv('d:/buldozer/things3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td> 30235.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>    12.682378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>    24.397954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>     0.721025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>     3.978690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>     6.613832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>    13.242001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>   676.477905</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0\n",
       "count  30235.000000\n",
       "mean      12.682378\n",
       "std       24.397954\n",
       "min        0.721025\n",
       "25%        3.978690\n",
       "50%        6.613832\n",
       "75%       13.242001\n",
       "max      676.477905"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(p).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
